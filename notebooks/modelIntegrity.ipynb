{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-05 20:41:25.300756: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-05 20:41:25.300827: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-05 20:41:25.301609: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14.0\n",
      "len(devices):  0\n",
      "available GPUs: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-05 20:41:29.289539: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import json\n",
    "\n",
    "#change working directory to root\n",
    "ROOT_DIR = os.getcwd()\n",
    "while os.path.basename(ROOT_DIR) != 'VisIrNet':\n",
    "    ROOT_DIR = os.path.abspath(os.path.join(ROOT_DIR,'..'))\n",
    "sys.path.insert(0,ROOT_DIR)\n",
    "os.chdir(ROOT_DIR)\n",
    "\n",
    "ROOT_DIR = Path(ROOT_DIR)\n",
    "\n",
    "print(tf.__version__)\n",
    "devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"len(devices): \", len(devices))\n",
    "print(f\"available GPUs: {devices}\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Tools.backboneUtils as backboneUtils\n",
    "import Tools.loss_functions as loss_functions\n",
    "import Tools.datasetTools as DatasetTools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataloaders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading train dataset\n",
      "[INFO] train _dataset:  27700\n",
      "[INFO] loading val dataset\n",
      "[INFO] val _dataset:  7990\n"
     ]
    }
   ],
   "source": [
    "import data_setup\n",
    "\n",
    "# try to import the dataset\n",
    "dataset=\"SkyData\"\n",
    "BATCH_SIZE = 2\n",
    "SHUFFLE_BUFFER_SIZE = 100\n",
    "\n",
    "train_dataloader,test_dataloader = data_setup.create_dataloaders(dataset=dataset, \n",
    "                                                                BATCH_SIZE=BATCH_SIZE,\n",
    "                                                                SHUFFLE_BUFFER_SIZE=100\n",
    "                                                                )\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_setup\n",
    "import Utils\n",
    "rgb_inputs_shape = (192,192,3)\n",
    "ir_inputs_shape =  (128,128,3)\n",
    "output_channels_per_block = 3\n",
    "regression_input_shape = (*rgb_inputs_shape[:2],output_channels_per_block*2)\n",
    "regression_output_shape = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_regression_input = tf.zeros((1,*regression_input_shape))\n",
    "# sample_backbone_input_rgb = tf.zeros((1,*rgb_inputs_shape))\n",
    "# sample_backbone_input_ir = tf.zeros((1,*ir_inputs_shape))\n",
    "# sample_regression_input.shape,sample_backbone_input_rgb.shape,sample_backbone_input_ir.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureEmbeddingBackBone = model_setup.getFeatureEmbeddingBackBone(rgb_inputs_shape=rgb_inputs_shape,\n",
    "                                                        ir_inputs_shape=ir_inputs_shape,\n",
    "                                                        output_channels_per_block=output_channels_per_block\n",
    "                                                        )\n",
    "\n",
    "regressionHead= model_setup.getRegressionHead(input_shape=regression_input_shape,\n",
    "                                                output_size=regression_output_shape\n",
    "                                                )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize and save model structures**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # visualize and save models\n",
    "\n",
    "# Utils.plot_and_save_model_structure(featureEmbeddingBackBone,\n",
    "#                                             save_path=\"resources/\",\n",
    "#                                             save_as=f\"featureEmbeddingBackBone\")\n",
    "# Utils.plot_and_save_model_structure(regressionHead,\n",
    "#                                             save_path=\"resources/\",\n",
    "#                                             save_as=f\"regressionHead\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Training**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nalain/miniconda3/envs/VisIrNet/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import engine \n",
    "\n",
    "initial_learning_rate = 0.001\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate,\n",
    "                                                                decay_steps=10000,\n",
    "                                                                decay_rate=0.96,\n",
    "                                                                staircase=True)\n",
    "NUM_EPOCHS = 1\n",
    "\n",
    "# Setup optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fir_frgb': 201382.19, 'fir_Iir': 136397.62, 'frgb_Irgb': 139784.28, 'fir_Irgb': 88976.28, 'frgb_Iir': 201382.19, 'ir_Irgb': 18158.422, 'total_loss': 430279.2}\n",
      "{'fir_frgb': 18572.82, 'fir_Iir': 5425.215, 'frgb_Irgb': 2123.418, 'fir_Irgb': 23496.57, 'frgb_Iir': 18572.82, 'ir_Irgb': 16178.701, 'total_loss': 44198.234}\n",
      "{'fir_frgb': 125560.82, 'fir_Iir': 2696.491, 'frgb_Irgb': 149734.36, 'fir_Irgb': 34165.234, 'frgb_Iir': 125560.82, 'ir_Irgb': 34848.05, 'total_loss': 309463.12}\n",
      "{'fir_frgb': 241356.36, 'fir_Iir': 25593.824, 'frgb_Irgb': 297382.88, 'fir_Irgb': 15821.648, 'frgb_Iir': 241356.36, 'ir_Irgb': 19590.766, 'total_loss': 554586.44}\n",
      "{'fir_frgb': 180376.06, 'fir_Iir': 25393.652, 'frgb_Irgb': 189224.56, 'fir_Irgb': 22275.96, 'frgb_Iir': 180376.06, 'ir_Irgb': 32810.92, 'total_loss': 391902.0}\n",
      "{'fir_frgb': 59253.25, 'fir_Iir': 6631.8164, 'frgb_Irgb': 62203.715, 'fir_Irgb': 14552.871, 'frgb_Iir': 59253.25, 'ir_Irgb': 23135.934, 'total_loss': 136016.47}\n",
      "{'fir_frgb': 19599.54, 'fir_Iir': 8914.159, 'frgb_Irgb': 3485.8477, 'fir_Irgb': 16881.803, 'frgb_Iir': 19599.54, 'ir_Irgb': 19139.482, 'total_loss': 39976.105}\n",
      "{'fir_frgb': 41477.38, 'fir_Iir': 2846.483, 'frgb_Irgb': 11708.361, 'fir_Irgb': 15367.494, 'frgb_Iir': 41477.38, 'ir_Irgb': 21486.574, 'total_loss': 68556.086}\n"
     ]
    }
   ],
   "source": [
    "# with tf.GradientTape() as tape:\n",
    "model = featureEmbeddingBackBone\n",
    "model.compile(optimizer=optimizer)\n",
    "dataloader=train_dataloader\n",
    "\n",
    "for batch in dataloader.take(8):\n",
    "        input_images, template_images, labels,_instances = batch\n",
    "\n",
    "        gt_matrix=DatasetTools.get_ground_truth_homographies(labels)\n",
    "        warped_inputs, _ = DatasetTools._get_warped_sampled(input_images, gt_matrix)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "                rgb_fmaps,ir_fmaps = model.call((input_images,template_images),training=True)\n",
    "        \n",
    "        \n",
    "                warped_fmaps,_ = DatasetTools._get_warped_sampled(rgb_fmaps, gt_matrix)\n",
    "                \n",
    "                # compute similarity losses                \n",
    "                _fir_frgb = loss_functions.compute_similarity_differences_mse(template_images, warped_fmaps)#should be minimal\n",
    "                _fir_Iir = loss_functions.compute_similarity_differences_mse(ir_fmaps,template_images)\n",
    "                _frgb_Irgb = loss_functions.compute_similarity_differences_mse(warped_fmaps,warped_inputs)#should be minimal\n",
    "                _fir_Irgb = loss_functions.compute_similarity_differences_mse(ir_fmaps,warped_inputs)#should be minimal\n",
    "                _frgb_Iir = loss_functions.compute_similarity_differences_mse(warped_fmaps,template_images)#\n",
    "                _Iir_Irgb = loss_functions.compute_similarity_differences_mse(template_images,warped_inputs)\n",
    "                \n",
    "                losses_weights = [1,.001,1,1,.0000001,.0000001]\n",
    "                losses = [_fir_frgb, _fir_Iir, _frgb_Irgb, _fir_Irgb, _frgb_Iir, _Iir_Irgb]\n",
    "                losses = [i*j for i,j in zip(losses,losses_weights)]\n",
    "                total_loss = tf.math.reduce_sum(losses)\n",
    "                \n",
    "                # loss shouldn't be nan\n",
    "                assert not np.isnan(total_loss.numpy()), \"Loss is NaN\"\n",
    "                \n",
    "        if(tf.math.reduce_any(tf.math.is_nan(rgb_fmaps)) or tf.math.reduce_any(tf.math.is_nan(ir_fmaps))):\n",
    "                print(\"fmaps1 or fmaps2 is nan\")\n",
    "                break     \n",
    "        \n",
    "        all_parameters= model.trainable_variables\n",
    "        grads = tape.gradient(total_loss, all_parameters)\n",
    "        grads = [tf.clip_by_value(i,-0.1,0.1) for i in grads]\n",
    "        optimizer.apply_gradients(zip(grads, all_parameters))\n",
    "        \n",
    "        # create losss dictionary\n",
    "        batch_losses = {\"fir_frgb\": _fir_frgb.numpy(),\n",
    "                        \"fir_Iir\": _fir_Iir.numpy(),\n",
    "                        \"frgb_Irgb\": _frgb_Irgb.numpy(),\n",
    "                        \"fir_Irgb\": _fir_Irgb.numpy(),\n",
    "                        \"frgb_Iir\": _frgb_Iir.numpy(),\n",
    "                        \"ir_Irgb\": _Iir_Irgb.numpy(),\n",
    "                        \"total_loss\": total_loss.numpy()}\n",
    "        print(batch_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "r,i,_,_ = next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=model.call((r,i),training=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VisIrNet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
