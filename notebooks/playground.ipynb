{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14.0\n",
      "len(devices):  0\n",
      "available GPUs: []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import json\n",
    "\n",
    "#change working directory to root\n",
    "ROOT_DIR = os.getcwd()\n",
    "while os.path.basename(ROOT_DIR) != 'VisIrNet':\n",
    "    ROOT_DIR = os.path.abspath(os.path.join(ROOT_DIR,'..'))\n",
    "sys.path.insert(0,ROOT_DIR)\n",
    "os.chdir(ROOT_DIR)\n",
    "\n",
    "ROOT_DIR = Path(ROOT_DIR)\n",
    "\n",
    "print(tf.__version__)\n",
    "devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"len(devices): \", len(devices))\n",
    "print(f\"available GPUs: {devices}\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataloaders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading train dataset\n",
      "[INFO] train _dataset:  27700\n",
      "[INFO] loading val dataset\n",
      "[INFO] val _dataset:  7990\n"
     ]
    }
   ],
   "source": [
    "import data_setup\n",
    "\n",
    "# try to import the dataset\n",
    "dataset=\"SkyData\"\n",
    "BATCH_SIZE = 2\n",
    "SHUFFLE_BUFFER_SIZE = 100\n",
    "\n",
    "train_dataloader,test_dataloader = data_setup.create_dataloaders(dataset=dataset, \n",
    "                                                                BATCH_SIZE=BATCH_SIZE,\n",
    "                                                                SHUFFLE_BUFFER_SIZE=100\n",
    "                                                                )\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_setup\n",
    "import Utils\n",
    "rgb_inputs_shape = (192,192,3)\n",
    "ir_inputs_shape =  (128,128,3)\n",
    "output_channels_per_block = 3\n",
    "regression_input_shape = (*rgb_inputs_shape[:2],output_channels_per_block*2)\n",
    "regression_output_shape = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureEmbeddingBackBone = model_setup.getFeatureEmbeddingBackBone(rgb_inputs_shape=rgb_inputs_shape,\n",
    "                                                        ir_inputs_shape=ir_inputs_shape,\n",
    "                                                        output_channels_per_block=output_channels_per_block\n",
    "                                                        )\n",
    "\n",
    "regressionHead= model_setup.getRegressionHead(input_shape=regression_input_shape,\n",
    "                                                output_size=regression_output_shape\n",
    "                                                )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize and save model structures**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # visualize and save models\n",
    "\n",
    "# Utils.plot_and_save_model_structure(featureEmbeddingBackBone,\n",
    "#                                             save_path=\"resources/\",\n",
    "#                                             save_as=f\"featureEmbeddingBackBone\")\n",
    "# Utils.plot_and_save_model_structure(regressionHead,\n",
    "#                                             save_path=\"resources/\",\n",
    "#                                             save_as=f\"regressionHead\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Training**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nalain/miniconda3/envs/VisIrNet/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] TrainingfeatureEmbeddingBackbone for 2 epochs\n",
      "[INFO] Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:10,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train_loss] : fir_frgb :41588.957|fir_Iir :99035.47|frgb_Irgb :23541.602|fir_Irgb :119831.8|frgb_Iir :41588.957|ir_Irgb :25170.664|total_loss :185061.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nalain/miniconda3/envs/VisIrNet/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test_loss] : fir_frgb :60999.83|fir_Iir :74608.17|frgb_Irgb :64984.05|fir_Irgb :48580.875|frgb_Iir :60999.83|ir_Irgb :26470.793|total_loss :174639.38\n",
      "[INFO] Saving model at models\n",
      "[INFO] Epoch 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:09,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train_loss] : fir_frgb :19682.773|fir_Iir :35949.527|frgb_Irgb :12828.844|fir_Irgb :32659.049|frgb_Iir :19682.773|ir_Irgb :20011.578|total_loss :65206.62\n",
      "[test_loss] : fir_frgb :14670.064|fir_Iir :11033.993|frgb_Irgb :2186.2651|fir_Irgb :38423.285|frgb_Iir :14670.064|ir_Irgb :20982.21|total_loss :55290.65\n",
      "[INFO] Saving model at models\n",
      "[INFO] Saving logs at logs\n",
      "Total training time : 29.699 seconds\n"
     ]
    }
   ],
   "source": [
    "import engine \n",
    "\n",
    "initial_learning_rate = 0.001\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate,\n",
    "                                                                decay_steps=10000,\n",
    "                                                                decay_rate=0.96,\n",
    "                                                                staircase=True)\n",
    "NUM_EPOCHS = 2\n",
    "\n",
    "# Setup optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "# Start the timer\n",
    "from timeit import default_timer as timer\n",
    "start_time = timer()\n",
    "# Train model \n",
    "\n",
    "model_results = engine.train_first_stage(model=featureEmbeddingBackBone,\n",
    "                                                train_dataloader=train_dataloader,\n",
    "                                                test_dataloader=test_dataloader,\n",
    "                                                optimizer=optimizer,\n",
    "                                                epochs=NUM_EPOCHS,\n",
    "                                                save_path=\"models\",\n",
    "                                                save_as=f\"featureEmbeddingBackBone\",\n",
    "                                                save_frequency=1,\n",
    "                                                save_hard_frequency=50\n",
    "                                                )\n",
    "# End the timer and print out how long it took\n",
    "end_time = timer()\n",
    "print(f\"Total training time : {end_time-start_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VisIrNet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
