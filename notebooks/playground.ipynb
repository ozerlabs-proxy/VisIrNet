{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14.0\n",
      "len(devices):  0\n",
      "available GPUs: []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import json\n",
    "\n",
    "#change working directory to root\n",
    "ROOT_DIR = os.getcwd()\n",
    "while os.path.basename(ROOT_DIR) != 'VisIrNet':\n",
    "    ROOT_DIR = os.path.abspath(os.path.join(ROOT_DIR,'..'))\n",
    "sys.path.insert(0,ROOT_DIR)\n",
    "os.chdir(ROOT_DIR)\n",
    "\n",
    "ROOT_DIR = Path(ROOT_DIR)\n",
    "\n",
    "print(tf.__version__)\n",
    "devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"len(devices): \", len(devices))\n",
    "print(f\"available GPUs: {devices}\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataloaders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading train dataset\n",
      "[INFO] train _dataset:  27700\n",
      "[INFO] loading val dataset\n",
      "[INFO] val _dataset:  7990\n"
     ]
    }
   ],
   "source": [
    "import data_setup\n",
    "\n",
    "# try to import the dataset\n",
    "dataset=\"SkyData\"\n",
    "BATCH_SIZE = 2\n",
    "SHUFFLE_BUFFER_SIZE = 100\n",
    "\n",
    "train_dataloader,test_dataloader = data_setup.create_dataloaders(dataset=dataset, \n",
    "                                                                BATCH_SIZE=BATCH_SIZE,\n",
    "                                                                SHUFFLE_BUFFER_SIZE=100\n",
    "                                                                )\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_setup\n",
    "import Utils\n",
    "rgb_inputs_shape = (192,192,3)\n",
    "ir_inputs_shape =  (128,128,3)\n",
    "output_channels_per_block = 3\n",
    "regression_input_shape = (*rgb_inputs_shape[:2],output_channels_per_block*2)\n",
    "regression_output_shape = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureEmbeddingBackBone = model_setup.getFeatureEmbeddingBackBone(rgb_inputs_shape=rgb_inputs_shape,\n",
    "                                                        ir_inputs_shape=ir_inputs_shape,\n",
    "                                                        output_channels_per_block=output_channels_per_block\n",
    "                                                        )\n",
    "\n",
    "regressionHead= model_setup.getRegressionHead(input_shape=regression_input_shape,\n",
    "                                                output_size=regression_output_shape\n",
    "                                                )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize and save model structures**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # visualize and save models\n",
    "\n",
    "# Utils.plot_and_save_model_structure(featureEmbeddingBackBone,\n",
    "#                                             save_path=\"resources/\",\n",
    "#                                             save_as=f\"featureEmbeddingBackBone\")\n",
    "# Utils.plot_and_save_model_structure(regressionHead,\n",
    "#                                             save_path=\"resources/\",\n",
    "#                                             save_as=f\"regressionHead\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Training**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nalain/miniconda3/envs/VisIrNet/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] TrainingfeatureEmbeddingBackbone for 2 epochs\n",
      "[INFO] Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:10,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train_loss] : fir_frgb :44145.918|fir_Iir :36047.496|frgb_Irgb :29143.664|fir_Irgb :49397.945|frgb_Iir :44145.918|ir_Irgb :22537.77|total_loss :122723.586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nalain/miniconda3/envs/VisIrNet/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test_loss] : fir_frgb :25025.096|fir_Iir :16693.922|frgb_Irgb :3220.5293|fir_Irgb :14421.654|frgb_Iir :25025.096|ir_Irgb :23883.51|total_loss :42683.977\n",
      "[INFO] Saving model at models\n",
      "[INFO] Epoch 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:09,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train_loss] : fir_frgb :22023.734|fir_Iir :21188.338|frgb_Irgb :7788.745|fir_Irgb :20434.357|frgb_Iir :22023.734|ir_Irgb :26260.39|total_loss :50268.03\n",
      "[test_loss] : fir_frgb :16552.176|fir_Iir :9733.266|frgb_Irgb :1917.4575|fir_Irgb :24527.33|frgb_Iir :16552.176|ir_Irgb :24651.746|total_loss :43006.703\n",
      "[INFO] Saving model at models\n",
      "[INFO] Saving logs at logs\n",
      "Total training time : 29.111 seconds\n"
     ]
    }
   ],
   "source": [
    "import engine \n",
    "\n",
    "initial_learning_rate = 0.001\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate,\n",
    "                                                                decay_steps=10000,\n",
    "                                                                decay_rate=0.96,\n",
    "                                                                staircase=True)\n",
    "NUM_EPOCHS = 2\n",
    "\n",
    "# Setup optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "# Start the timer\n",
    "from timeit import default_timer as timer\n",
    "start_time = timer()\n",
    "# Train model \n",
    "\n",
    "model_results = engine.train_first_stage(model=featureEmbeddingBackBone,\n",
    "                                                train_dataloader=train_dataloader,\n",
    "                                                test_dataloader=test_dataloader,\n",
    "                                                optimizer=optimizer,\n",
    "                                                epochs=NUM_EPOCHS,\n",
    "                                                save_path=\"models\",\n",
    "                                                save_as=f\"featureEmbeddingBackBone\",\n",
    "                                                save_frequency=1,\n",
    "                                                save_hard_frequency=50\n",
    "                                                )\n",
    "# End the timer and print out how long it took\n",
    "end_time = timer()\n",
    "print(f\"Total training time : {end_time-start_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.14 hours'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VisIrNet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
